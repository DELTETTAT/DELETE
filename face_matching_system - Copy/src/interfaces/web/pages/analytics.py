import os
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import sys
import os
# Add the src directory to path
src_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '../..'))
sys.path.insert(0, src_path)

from core.indexing.manager import IndexManager
from core.search.engine import SearchEngine
from utils.filesystem.operations import FileSystemOperations
from config.settings import Settings

def render_analytics_page():
    """Render the analytics and statistics page"""
    
    settings = Settings()
    fs_ops = FileSystemOperations()
    
    st.markdown('<h1 class="main-header">üìà Analytics & Statistics</h1>', unsafe_allow_html=True)
    
    # Initialize components
    index_manager = IndexManager()
    search_engine = SearchEngine()
    
    # Check if system is ready
    if not index_manager.index_exists():
        st.warning("‚ùå No index found. Analytics require a built index.")
        st.info("Please build an index first using the Index Management page.")
        return
    
    # Main analytics tabs
    tab1, tab2, tab3, tab4 = st.tabs(["üìä System Overview", "üìà Index Analytics", "üîç Search Performance", "üìÅ File Statistics"])
    
    with tab1:
        render_system_overview(index_manager, search_engine, fs_ops, settings)
    
    with tab2:
        render_index_analytics(index_manager)
    
    with tab3:
        render_search_performance(search_engine)
    
    with tab4:
        render_file_statistics(fs_ops, settings)

def render_system_overview(index_manager, search_engine, fs_ops, settings):
    """Render system overview analytics"""
    
    st.markdown("## üìä System Overview")
    
    # Get comprehensive statistics
    index_stats = index_manager.get_index_stats()
    search_stats = search_engine.get_search_stats()
    
    # Key metrics
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            "Total Indexed Faces", 
            index_stats.get('total_faces', 0),
            help="Number of faces successfully indexed"
        )
    
    with col2:
        success_rate = 0
        if index_stats.get('total_images', 0) > 0:
            success_rate = (index_stats.get('successful_embeddings', 0) / index_stats.get('total_images', 1)) * 100
        st.metric(
            "Success Rate", 
            f"{success_rate:.1f}%",
            help="Percentage of images successfully processed"
        )
    
    with col3:
        st.metric(
            "Embedding Dimension", 
            index_stats.get('embedding_dimension', 0),
            help="Dimension of face embeddings"
        )
    
    with col4:
        index_size_mb = index_stats.get('index_file_size', 0) / (1024 * 1024) if index_stats.get('index_file_size') else 0
        st.metric(
            "Index Size", 
            f"{index_size_mb:.2f} MB",
            help="Size of FAISS index file"
        )
    
    st.markdown("---")
    
    # System health indicators
    st.markdown("### üè• System Health")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Processing success rate chart
        if index_stats.get('total_images', 0) > 0:
            success_data = {
                'Status': ['Successful', 'Failed'],
                'Count': [
                    index_stats.get('successful_embeddings', 0),
                    index_stats.get('failed_embeddings', 0)
                ]
            }
            
            fig = px.pie(
                success_data, 
                values='Count', 
                names='Status',
                title="Processing Success Rate",
                color_discrete_map={'Successful': '#28a745', 'Failed': '#dc3545'}
            )
            fig.update_traces(textposition='inside', textinfo='percent+label')
            st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        # System configuration
        st.markdown("#### Configuration Details")
        config_data = {
            "Model": index_stats.get('model_used', 'Unknown'),
            "Detector": index_stats.get('detector_used', 'Unknown'),
            "Preprocessing": "Yes" if index_stats.get('preprocessing_used') else "No",
            "Created": index_stats.get('created_at', 'Unknown')[:10] if index_stats.get('created_at') else 'Unknown'
        }
        
        for key, value in config_data.items():
            st.write(f"**{key}:** {value}")

def render_index_analytics(index_manager):
    """Render index-specific analytics"""
    
    st.markdown("## üìà Index Analytics")
    
    index_stats = index_manager.get_index_stats()
    
    # Index composition
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### üìä Index Composition")
        
        # Create sample distribution data based on available stats
        if index_stats.get('total_faces', 0) > 0:
            # Simulate folder distribution (since we don't have actual folder stats)
            total_faces = index_stats.get('total_faces', 0)
            
            # Create a simple visualization of index size vs dimension
            dimension_data = {
                'Metric': ['Indexed Faces', 'Total Capacity (est.)', 'Embedding Dimension'],
                'Value': [
                    total_faces,
                    total_faces * 2,  # Estimated capacity
                    index_stats.get('embedding_dimension', 0)
                ]
            }
            
            fig = go.Figure()
            fig.add_trace(go.Bar(
                x=dimension_data['Metric'],
                y=dimension_data['Value'],
                marker_color=['#1f77b4', '#ff7f0e', '#2ca02c']
            ))
            fig.update_layout(
                title="Index Metrics",
                yaxis_title="Count"
            )
            st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        st.markdown("### üìã Index Details")
        
        # Detailed index information
        details = {
            "Index Type": "FAISS IndexFlatL2",
            "Distance Metric": "L2 (Euclidean)",
            "Storage Format": "Binary",
            "Memory Usage": "In-Memory + Disk",
            "Search Complexity": "O(n)",
            "Insert Complexity": "O(1)"
        }
        
        for key, value in details.items():
            st.write(f"**{key}:** {value}")
    
    # Timeline if creation date is available
    if index_stats.get('created_at'):
        st.markdown("### üìÖ Index Timeline")
        
        try:
            created_date = datetime.fromisoformat(index_stats['created_at'].replace('Z', '+00:00'))
            current_date = datetime.now()
            age_days = (current_date - created_date).days
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Index Age", f"{age_days} days")
            with col2:
                st.metric("Created", created_date.strftime("%Y-%m-%d"))
            with col3:
                st.metric("Last Modified", "Today")  # Simplified
                
        except Exception:
            st.write("Timeline information unavailable")

def render_search_performance(search_engine):
    """Render search performance analytics"""
    
    st.markdown("## üîç Search Performance")
    
    if not search_engine.is_ready():
        st.warning("Search engine not ready")
        return
    
    search_stats = search_engine.get_search_stats()
    
    # Search engine metrics
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric(
            "Searchable Faces",
            search_stats.get('total_indexed_faces', 0)
        )
    
    with col2:
        st.metric(
            "Search Model",
            search_stats.get('model_name', 'Unknown')
        )
    
    with col3:
        st.metric(
            "Search Ready",
            "‚úÖ Yes" if search_stats.get('index_loaded') else "‚ùå No"
        )
    
    # Performance characteristics
    st.markdown("### ‚ö° Performance Characteristics")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Theoretical performance metrics
        total_faces = search_stats.get('total_indexed_faces', 0)
        
        perf_data = {
            'Operation': ['Single Search', 'Batch Search (10)', 'Index Load', 'Memory Usage'],
            'Estimated Time': ['~50ms', '~200ms', '~1s', f'~{total_faces * 0.002:.1f}MB']
        }
        
        perf_df = pd.DataFrame(perf_data)
        st.dataframe(perf_df, use_container_width=True)
    
    with col2:
        # Search complexity visualization
        if total_faces > 0:
            complexity_data = {
                'Index Size': list(range(100, total_faces + 100, max(1, total_faces // 10))),
                'Search Time (ms)': [size * 0.05 for size in range(100, total_faces + 100, max(1, total_faces // 10))]
            }
            
            fig = px.line(
                complexity_data,
                x='Index Size',
                y='Search Time (ms)',
                title="Search Time vs Index Size",
                labels={'Index Size': 'Number of Faces', 'Search Time (ms)': 'Time (ms)'}
            )
            st.plotly_chart(fig, use_container_width=True)
    
    # Search quality metrics
    st.markdown("### üéØ Search Quality")
    
    quality_metrics = {
        "Distance Metric": "L2 Euclidean Distance",
        "Similarity Range": "0.0 - 1000.0",
        "Recommended Threshold": "450.0",
        "False Positive Rate": "< 5% (estimated)",
        "False Negative Rate": "< 10% (estimated)"
    }
    
    for metric, value in quality_metrics.items():
        st.write(f"**{metric}:** {value}")

def render_file_statistics(fs_ops, settings):
    """Render file system statistics"""
    
    st.markdown("## üìÅ File Statistics")
    
    # Directory analysis
    directories = {
        "Source": st.session_state.get('custom_folder_path', ''),
        "Uploads": settings.UPLOAD_DIR,
        "Preprocessed": settings.PREPROCESSED_DIR,
        "Embeddings": settings.EMBED_DIR,
        "Temp": settings.TEMP_DIR
    }
    
    # Collect directory statistics
    dir_stats = []
    total_images = 0
    total_size = 0
    
    for name, path in directories.items():
        if path and os.path.exists(path):
            image_count = fs_ops.count_images_in_folder(path)
            dir_size = get_directory_size(path)
            
            dir_stats.append({
                'Directory': name,
                'Images': image_count,
                'Size (MB)': dir_size,
                'Path': path
            })
            
            total_images += image_count
            total_size += dir_size
        else:
            dir_stats.append({
                'Directory': name,
                'Images': 0,
                'Size (MB)': 0,
                'Path': path or 'Not set'
            })
    
    # Summary metrics
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("Total Images", total_images)
    with col2:
        st.metric("Total Size", f"{total_size:.2f} MB")
    with col3:
        st.metric("Active Directories", len([d for d in dir_stats if d['Images'] > 0]))
    
    # Directory breakdown
    st.markdown("### üìä Directory Breakdown")
    
    if dir_stats:
        df = pd.DataFrame(dir_stats)
        
        # Directory size chart
        fig = px.bar(
            df[df['Images'] > 0], 
            x='Directory', 
            y='Images',
            title="Images per Directory",
            color='Images',
            color_continuous_scale='viridis'
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # Detailed table
        st.dataframe(df, use_container_width=True)
    
    # File type analysis
    st.markdown("### üìÑ File Type Analysis")
    
    if st.session_state.get('custom_folder_path'):
        file_types = analyze_file_types(st.session_state.custom_folder_path)
        
        if file_types:
            fig = px.pie(
                values=list(file_types.values()),
                names=list(file_types.keys()),
                title="File Type Distribution"
            )
            st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("Set a source folder to see file type analysis")
    
    # Storage recommendations
    st.markdown("### üí° Storage Recommendations")
    
    recommendations = []
    
    if total_size > 1000:  # > 1GB
        recommendations.append("üî∏ Consider archiving old preprocessed images to save space")
    
    if total_images > 10000:
        recommendations.append("üî∏ Large dataset detected - consider database storage for metadata")
    
    temp_size = next((d['Size (MB)'] for d in dir_stats if d['Directory'] == 'Temp'), 0)
    if temp_size > 100:
        recommendations.append("üî∏ Temp directory is large - consider cleanup")
    
    if not recommendations:
        recommendations.append("‚úÖ Storage usage looks optimal")
    
    for rec in recommendations:
        st.write(rec)

def get_directory_size(dir_path):
    """Calculate directory size in MB"""
    try:
        total_size = 0
        for dirpath, dirnames, filenames in os.walk(dir_path):
            for filename in filenames:
                filepath = os.path.join(dirpath, filename)
                if os.path.exists(filepath):
                    total_size += os.path.getsize(filepath)
        return total_size / (1024 * 1024)  # Convert to MB
    except Exception:
        return 0.0

def analyze_file_types(directory):
    """Analyze file types in a directory"""
    try:
        file_types = {}
        for root, dirs, files in os.walk(directory):
            for file in files:
                ext = os.path.splitext(file)[1].lower()
                if ext:
                    file_types[ext] = file_types.get(ext, 0) + 1
        
        # Group by image types
        image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.gif', '.webp'}
        grouped_types = {}
        
        for ext, count in file_types.items():
            if ext in image_extensions:
                grouped_types[ext] = count
            else:
                grouped_types['Other'] = grouped_types.get('Other', 0) + count
        
        return grouped_types
    except Exception:
        return {}
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
import pandas as pd
import sys
import os

# Add the src directory to path
src_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '../..'))
sys.path.insert(0, src_path)

from core.orchestrator import FaceMatchingOrchestrator
from utils.filesystem.operations import FileSystemOperations
from config.settings import Settings

def render_analytics_page():
    """Render the analytics page"""
    
    st.markdown('<h1 class="main-header">üìà Analytics</h1>', unsafe_allow_html=True)
    
    # Initialize components
    orchestrator = FaceMatchingOrchestrator()
    fs_ops = FileSystemOperations()
    settings = Settings()
    
    # Get system status
    system_status = orchestrator.get_system_status()
    index_status = system_status.get('index', {})
    
    if not index_status.get('ready', False):
        st.warning("‚ùå No index found. Analytics are not available without a built index.")
        return
    
    # Get comprehensive statistics
    stats = orchestrator.get_index_statistics()
    
    # Display key metrics
    st.markdown("## üìä Key Metrics")
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Total Faces", stats.get('total_faces', 0))
    with col2:
        st.metric("Total Images", stats.get('total_images', 0))
    with col3:
        success_rate = (stats.get('successful_embeddings', 0) / max(stats.get('total_images', 1), 1)) * 100
        st.metric("Success Rate", f"{success_rate:.1f}%")
    with col4:
        st.metric("Failed Extractions", stats.get('failed_embeddings', 0))
    
    st.markdown("---")
    
    # Index Information
    st.markdown("## üîç Index Information")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### Technical Details")
        st.write(f"**Model Used:** {stats.get('model_used', 'Unknown')}")
        st.write(f"**Detector Backend:** {stats.get('detector_used', 'Unknown')}")
        st.write(f"**Embedding Dimension:** {stats.get('embedding_dimension', 'Unknown')}")
        st.write(f"**Index Size:** {stats.get('index_size', 0)}")
    
    with col2:
        st.markdown("### Build Information")
        st.write(f"**Source Folder:** {stats.get('source_folder', 'Unknown')}")
        st.write(f"**Created At:** {stats.get('created_at', 'Unknown')}")
        st.write(f"**Preprocessing Used:** {'Yes' if stats.get('preprocessing_used') else 'No'}")
        
        if 'index_file_size' in stats:
            file_size_mb = stats['index_file_size'] / 1024 / 1024
            st.write(f"**Index File Size:** {file_size_mb:.2f} MB")
    
    # Success/Failure Analysis
    if stats.get('total_images', 0) > 0:
        st.markdown("---")
        st.markdown("## üìà Processing Analysis")
        
        # Create success/failure pie chart
        successful = stats.get('successful_embeddings', 0)
        failed = stats.get('failed_embeddings', 0)
        
        if successful > 0 or failed > 0:
            fig = go.Figure(data=[go.Pie(
                labels=['Successful', 'Failed'],
                values=[successful, failed],
                hole=0.3,
                marker_colors=['#28a745', '#dc3545']
            )])
            
            fig.update_layout(
                title="Image Processing Results",
                annotations=[dict(text='Processing', x=0.5, y=0.5, font_size=20, showarrow=False)]
            )
            
            st.plotly_chart(fig, use_container_width=True)
    
    # Directory Status
    st.markdown("---")
    st.markdown("## üìÅ Directory Status")
    
    directories = system_status.get('directories', {})
    
    dir_data = []
    for dir_name, dir_info in directories.items():
        dir_data.append({
            'Directory': dir_name.replace('_', ' ').title(),
            'Exists': '‚úÖ' if dir_info.get('exists', False) else '‚ùå',
            'Path': dir_info.get('path', 'Unknown'),
            'Image Count': dir_info.get('image_count', 0)
        })
    
    if dir_data:
        df = pd.DataFrame(dir_data)
        st.dataframe(df, use_container_width=True)
    
    # Component Status
    st.markdown("---")
    st.markdown("## üîß Component Status")
    
    components = system_status.get('components', {})
    
    comp_data = []
    for comp_name, comp_info in components.items():
        status = '‚úÖ Ready' if comp_info.get('initialized', False) else '‚ùå Not Ready'
        details = []
        
        if 'model' in comp_info:
            details.append(f"Model: {comp_info['model']}")
        if 'detector' in comp_info:
            details.append(f"Detector: {comp_info['detector']}")
        
        comp_data.append({
            'Component': comp_name.replace('_', ' ').title(),
            'Status': status,
            'Details': ', '.join(details) if details else 'N/A'
        })
    
    if comp_data:
        df_comp = pd.DataFrame(comp_data)
        st.dataframe(df_comp, use_container_width=True)
    
    # Refresh button
    st.markdown("---")
    if st.button("üîÑ Refresh Analytics", type="primary"):
        st.cache_data.clear()
        st.rerun()
